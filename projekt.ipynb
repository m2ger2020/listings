{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "data = pd.read_csv('techscene.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Andmete puhastamine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data.columns:#teeme kõik väiketähtedeks\n",
    "  data[column]=data[column].str.lower()\n",
    "#job_name\n",
    "#eemaldame (m/f/d),(m/f/x),| SEB, Tallinn,\n",
    "data['job_name']=data['job_name'].str.replace('(m/f/d)', '').replace('(m/f/x)','').replace('| SEB, Tallinn','').replace('\\\"','')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['software-development', nan, 'front-end', 'back-end', 'mobile',\n",
       "       'analytics', 'full-stack', 'other', 'devops-sre', 'data-science',\n",
       "       'cyber-security', 'ai-ml', 'qa', 'sales', 'finance', 'marketing',\n",
       "       'design', 'hr', 'customer-support', 'management'], dtype=object)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['domain'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in data[data['domain'].isna()].iterrows():#lisame valdkonna kõikjale, kus domain on NaN\n",
    "  name=row['job_name']\n",
    "  if re.search('software engineer|tarkvaraarendaja',name):\n",
    "    print('replaced ',str(index))\n",
    "    data.loc[index,'domain']='software-development'\n",
    "  elif re.search('front-end|frontend|react',name):\n",
    "    data.loc[index,'domain']='front-end'\n",
    "  elif re.search('back-end|backend',name):\n",
    "    data.loc[index,'domain']='back-end'\n",
    "  elif re.search('android|ios',name):\n",
    "    data.loc[index,'domain']='mobile'\n",
    "  elif re.search('devops',name):\n",
    "    data.loc[index,'domain']='devops-sre'\n",
    "  elif re.search('data scientist',name):\n",
    "    data.loc[index,'domain']='data-science'\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_name</th>\n",
       "      <th>job_link</th>\n",
       "      <th>date_added</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nexd</td>\n",
       "      <td>full-stack developer (php, vue.js)</td>\n",
       "      <td>https://www.nexd.com/career/full-stack-developer/</td>\n",
       "      <td>2024-03-26 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>nexd</td>\n",
       "      <td>full-stack developer (php, vue.js)</td>\n",
       "      <td>https://www.nexd.com/career/full-stack-developer/</td>\n",
       "      <td>2024-03-26 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>novater solutions</td>\n",
       "      <td>full-stack developer</td>\n",
       "      <td>https://novater.com/careers/full-stack-developer/</td>\n",
       "      <td>2024-03-26 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>seb</td>\n",
       "      <td>full-stack software developer for baltic inter...</td>\n",
       "      <td>https://jobs.eu.lever.co/seb/2b1135be-e2e0-4f7...</td>\n",
       "      <td>2024-03-26 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>creditstar</td>\n",
       "      <td>full stack developer</td>\n",
       "      <td>https://apply.workable.com/j/9c81ddebd2</td>\n",
       "      <td>2024-03-26 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>luminor</td>\n",
       "      <td>senior compliance officer (assurance unit)</td>\n",
       "      <td>https://luminorbank.teamtailor.com/jobs/354120...</td>\n",
       "      <td>2024-04-02 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>cybernetica</td>\n",
       "      <td>post-quantum cryptography engineer</td>\n",
       "      <td>https://cyber.teamdash.com/p/job/iqn79wzx/post...</td>\n",
       "      <td>2024-04-02 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>cybernetica</td>\n",
       "      <td>researcher</td>\n",
       "      <td>https://cyber.teamdash.com/p/job/pagseczx/rese...</td>\n",
       "      <td>2024-04-02 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>cybernetica</td>\n",
       "      <td>data architect</td>\n",
       "      <td>https://cyber.teamdash.com/p/job/knvredgr/data...</td>\n",
       "      <td>2024-04-02 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>cybernetica</td>\n",
       "      <td>client specialist</td>\n",
       "      <td>https://cyber.teamdash.com/p/job/vdd4brre/clie...</td>\n",
       "      <td>2024-04-02 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>597 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          company_name                                           job_name  \\\n",
       "6                 nexd                 full-stack developer (php, vue.js)   \n",
       "27                nexd                 full-stack developer (php, vue.js)   \n",
       "29   novater solutions                               full-stack developer   \n",
       "30                 seb  full-stack software developer for baltic inter...   \n",
       "31          creditstar                               full stack developer   \n",
       "..                 ...                                                ...   \n",
       "737            luminor         senior compliance officer (assurance unit)   \n",
       "738        cybernetica                 post-quantum cryptography engineer   \n",
       "739        cybernetica                                         researcher   \n",
       "740        cybernetica                                     data architect   \n",
       "741        cybernetica                                  client specialist   \n",
       "\n",
       "                                              job_link           date_added  \\\n",
       "6    https://www.nexd.com/career/full-stack-developer/  2024-03-26 00:00:00   \n",
       "27   https://www.nexd.com/career/full-stack-developer/  2024-03-26 00:00:00   \n",
       "29   https://novater.com/careers/full-stack-developer/  2024-03-26 00:00:00   \n",
       "30   https://jobs.eu.lever.co/seb/2b1135be-e2e0-4f7...  2024-03-26 00:00:00   \n",
       "31             https://apply.workable.com/j/9c81ddebd2  2024-03-26 00:00:00   \n",
       "..                                                 ...                  ...   \n",
       "737  https://luminorbank.teamtailor.com/jobs/354120...  2024-04-02 00:00:00   \n",
       "738  https://cyber.teamdash.com/p/job/iqn79wzx/post...  2024-04-02 00:00:00   \n",
       "739  https://cyber.teamdash.com/p/job/pagseczx/rese...  2024-04-02 00:00:00   \n",
       "740  https://cyber.teamdash.com/p/job/knvredgr/data...  2024-04-02 00:00:00   \n",
       "741  https://cyber.teamdash.com/p/job/vdd4brre/clie...  2024-04-02 00:00:00   \n",
       "\n",
       "    domain  \n",
       "6      NaN  \n",
       "27     NaN  \n",
       "29     NaN  \n",
       "30     NaN  \n",
       "31     NaN  \n",
       "..     ...  \n",
       "737    NaN  \n",
       "738    NaN  \n",
       "739    NaN  \n",
       "740    NaN  \n",
       "741    NaN  \n",
       "\n",
       "[597 rows x 5 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['domain'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Groups data by company name, job name, and job link. \n",
    "Sorts the data by date added and creates blocks of consecutive job postings.\n",
    "\"\"\"\n",
    "\n",
    "def process_job_data(data):\n",
    "    data['date_added'] = pd.to_datetime(data['date_added']).dt.date\n",
    "\n",
    "    # Normalize text for comparison\n",
    "    data['job_name'] = data['job_name'].str.lower()\n",
    "    data['company_name'] = data['company_name'].str.lower()\n",
    "\n",
    "    # Remove exact duplicates\n",
    "    data = data.drop_duplicates()\n",
    "\n",
    "    # Create an empty DataFrame with specified columns\n",
    "    new_data = pd.DataFrame(columns=[\"company_name\", \"job_name\", \"domain\", \"first_appeared\", \"last_appeared\", \"job_link\"])\n",
    "\n",
    "    grouped = data.groupby([\"company_name\", \"job_name\", \"job_link\"])\n",
    "    \n",
    "    for (company_name, job_name, job_link), group in grouped:\n",
    "        group = group.sort_values('date_added')\n",
    "\n",
    "        start_date = None\n",
    "        prev_date = None\n",
    "\n",
    "        # Get domain if exists in the group\n",
    "        domain = group['domain'].dropna().iloc[0] if not group['domain'].dropna().empty else None\n",
    "\n",
    "        for current_date in group['date_added']:\n",
    "            if start_date is None:\n",
    "                start_date = current_date\n",
    "                prev_date = current_date\n",
    "            elif (current_date - prev_date).days > 1:\n",
    "                # Special case: check only for 2024-09-06\n",
    "                if (prev_date == pd.to_datetime('2024-09-05').date() and \n",
    "                    current_date == pd.to_datetime('2024-09-07').date()):\n",
    "                    prev_date = current_date  # Assume continuity\n",
    "                else:\n",
    "                    # Save current block if gap is not special case\n",
    "                    new_data = pd.concat([new_data, pd.DataFrame({\n",
    "                        \"company_name\": [company_name],\n",
    "                        \"job_name\": [job_name],\n",
    "                        \"domain\": [domain],\n",
    "                        \"first_appeared\": [start_date],\n",
    "                        \"last_appeared\": [prev_date],\n",
    "                        \"job_link\": [job_link]\n",
    "                    })], ignore_index=True)\n",
    "                    start_date = current_date\n",
    "\n",
    "                start_date = current_date  # Start a new block\n",
    "\n",
    "            prev_date = current_date\n",
    "\n",
    "        # Save the last block\n",
    "        new_data = pd.concat([new_data, pd.DataFrame({\n",
    "            \"company_name\": [company_name],\n",
    "            \"job_name\": [job_name],\n",
    "            \"domain\": [domain],\n",
    "            \"first_appeared\": [start_date],\n",
    "            \"last_appeared\": [prev_date],\n",
    "            \"job_link\": [job_link]\n",
    "        })], ignore_index=True)\n",
    "\n",
    "    return new_data\n",
    "\n",
    "# Example usage:\n",
    "# data = pd.read_csv('input.csv')\n",
    "processed_data = process_job_data(data)\n",
    "processed_data.to_csv('new_data!!!.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Groups data by company name, job name, and job link.\n",
    "Finds the first apperance and last apperance dates.\n",
    "\"\"\"\n",
    "\n",
    "def process_job_data(data):\n",
    "    data['date_added'] = pd.to_datetime(data['date_added']).dt.date\n",
    "\n",
    "    # Create an empty DataFrame with specified columns\n",
    "    new_data = pd.DataFrame(columns=[\"company_name\", \"job_name\", \"domain\", \"first_appeared\", \"last_appeared\", \"job_link\"])\n",
    "    \n",
    "    # Group by unique identifying columns\n",
    "    grouped = data.groupby([\"company_name\", \"job_name\", \"job_link\"])\n",
    "    \n",
    "    # Iterate through each unique group\n",
    "    for (company_name, job_name, job_link), group in grouped:\n",
    "        # Find the first and last appearance dates\n",
    "        first_appeared = group['date_added'].min()\n",
    "        last_appeared = group['date_added'].max()\n",
    "        \n",
    "\n",
    "        # Get domain if exists in the group\n",
    "        domain = group['domain'].dropna().iloc[0] if not group['domain'].dropna().empty else None\n",
    "\n",
    "        # Create a new row for this unique entry\n",
    "        new_row = pd.DataFrame({\n",
    "            \"company_name\": [company_name],\n",
    "            \"job_name\": [job_name],\n",
    "            \"domain\": [domain],\n",
    "            \"first_appeared\": [first_appeared],\n",
    "            \"last_appeared\": [last_appeared],\n",
    "            \"job_link\": [job_link]\n",
    "        })\n",
    "        \n",
    "        # Append to new_data\n",
    "        new_data = pd.concat([new_data, new_row], ignore_index=True)\n",
    "    \n",
    "    return new_data\n",
    "\n",
    "# Example usage\n",
    "# data = pd.read_csv('your_input_file.csv')  # Load your input data\n",
    "nd = data.copy()\n",
    "new_data = process_job_data(data)\n",
    "new_data.to_csv('new_data!!!!!!!.csv', index=False)  # Save processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Checks if first data has the same links as second data.\n",
    "\"\"\"\n",
    "def chek_links(data, data2):\n",
    "\n",
    "    links1 = data[\"job_link\"].unique()\n",
    "    links2 = data2[\"job_link\"].unique()\n",
    "    for link in links1:\n",
    "        if link not in links2:\n",
    "            print(link)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IDS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
